<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jayanth on Jayanth</title>
    <link>https://jayanthrr.github.io/</link>
    <description>Recent content in Jayanth on Jayanth</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Wed, 20 Apr 2016 00:00:00 +0000</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Stochastic Shortest Path</title>
      <link>https://jayanthrr.github.io/project/stochastic/</link>
      <pubDate>Fri, 09 Mar 2018 02:03:50 -0500</pubDate>
      
      <guid>https://jayanthrr.github.io/project/stochastic/</guid>
      <description>&lt;p&gt;I am currently working on a stochastic shortest path problem in an urban traffic scenario, considering the topological relations between the roads.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Traffic Sign Classification</title>
      <link>https://jayanthrr.github.io/project/trafficsign/</link>
      <pubDate>Fri, 09 Mar 2018 01:38:11 -0500</pubDate>
      
      <guid>https://jayanthrr.github.io/project/trafficsign/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Course Recommender Engine</title>
      <link>https://jayanthrr.github.io/project/recommender/</link>
      <pubDate>Thu, 08 Mar 2018 22:46:44 -0500</pubDate>
      
      <guid>https://jayanthrr.github.io/project/recommender/</guid>
      <description>&lt;p&gt;Built a collaborative filtering based recommender system for selecting courses based on the user&amp;rsquo;s past history using apache spark&amp;rsquo;s MLlib. Developed and demostrated a working prototype in 24 hours during Hack OH/IO 2016.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Fake News Challenge- stage 1</title>
      <link>https://jayanthrr.github.io/project/fnc/</link>
      <pubDate>Thu, 08 Mar 2018 22:32:58 -0500</pubDate>
      
      <guid>https://jayanthrr.github.io/project/fnc/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Connected and Autonomous Traffic Simulator</title>
      <link>https://jayanthrr.github.io/project/cats/</link>
      <pubDate>Thu, 08 Mar 2018 22:29:56 -0500</pubDate>
      
      <guid>https://jayanthrr.github.io/project/cats/</guid>
      <description>&lt;p&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/259290467&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/259290463&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/259290465&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/259290444&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/259290451&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Rollout: Approximate Dynamic Programming</title>
      <link>https://jayanthrr.github.io/post/rollout/</link>
      <pubDate>Tue, 27 Feb 2018 14:29:56 -0500</pubDate>
      
      <guid>https://jayanthrr.github.io/post/rollout/</guid>
      <description>

&lt;p&gt;&lt;em&gt;Life can only be understood going backwards, but it must be lived going forwards - Kierkegaard&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Dynamic Programming is a mathematical technique that is used in several fields of research including economics, finance, engineering. It deals with making decisions over different stages of the problem in order to minimize (or maximize) a corresponding cost function (or reward). The outcome of a decision at a given stage can be fully predicted (deterministic) or can only be partially predicted (with randomness involved). One key aspect of such problems is the trade off in optimizing the cost incurred at the current stage and the cost to be incurred at a future stage.&lt;/p&gt;

&lt;p&gt;Dynamic Programming is very helpful in many contexts by providing an exact solution, however, when the problem size increases, it requires enormous amount of storage and computational time (often referred to as the &lt;em&gt;curse of dimensionality&lt;/em&gt;) which makes it infeasible to apply to practical situations. Often in such situations, one may not desire an exact solution, but an approximately optimal (or suboptimal) solution. Then there must be a better class of techniques that can capture this trade off between feasibility and sub optimality. These techniques are collectively referred to as &lt;em&gt;Approximate Dynamic Programming&lt;/em&gt; or &lt;em&gt;Reinforcement Learning&lt;/em&gt; (in the field of AI) or &lt;em&gt;Neuro Dynamic Programming&lt;/em&gt; (in the field of automatic control), all of which essentially mean the same.&lt;/p&gt;

&lt;p&gt;In this blog post, we shall look at a specific technique called &lt;em&gt;Rollout Algorithm&lt;/em&gt; that is quite extensively used (with surprisingly good results). In fact, &lt;a href=&#34;https://www.nature.com/articles/nature16961&#34; target=&#34;_blank&#34;&gt;Mastering the game of Go, DeepMind&lt;/a&gt; uses a variant of &lt;em&gt;Rollout&lt;/em&gt; called &lt;em&gt;Monte Carlo Tree Search&lt;/em&gt;. We shall first formulate a DP problem, state the DP algorithm and illustrate with an example the infeasibility of DP. Using the same example, we shall study how &lt;em&gt;Rollout&lt;/em&gt; offers an effective solution that optimizes the trade-off between accuracy and computation. This post is entirely based on my reading of the book &lt;a href=&#34;http://web.mit.edu/dimitrib/www/dpchapter.html&#34; target=&#34;_blank&#34;&gt;Approximate Dynamic Programming&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&#34;dp-formulation&#34;&gt;DP formulation&lt;/h1&gt;

&lt;p&gt;In this post, we shall focus only on finite horizon problems (problems involving a finite number of stages or time steps at which a decision is taken). We denote the state of the system at time $k$ as $x{_k}$ (belongs to a space $S{_k}$ ), and the decision (or control) taken as $u{_k}$ (belongs to a space $U{_k} (x{_k}) $ ), and a random variable $w{_k}$ (which is independent of other $w{_i}$) that affects the system. The system has the form&lt;/p&gt;

&lt;p&gt;$$x_{k+1} = f_{k}(x_{k}, u_{k}, w_{k})$$&lt;/p&gt;

&lt;p&gt;where $k$ takes a value between $0$ and $N$ (finite horizon). At each stage, there is a cost incurred $g{_k}(x{_k}, u{_k}, w{_k})$ which accumulates over time. The total cost incurred is then&lt;/p&gt;

&lt;p&gt;$$ g_{N}(x_{N}) + \sum_{k=0}^{N-1}g_{k}(x_{k}, u_{k}, w_{k})$$&lt;/p&gt;

&lt;p&gt;where $g {_N}(x{_N})$ is a terminal cost incurred at the final stage (it only depends on the state, and no action is to be taken). The objective of the problem is to find an optimal policy&lt;/p&gt;

&lt;p&gt;$$\pi:= {\mu_{0},..,\mu_{k},.. \mu_{N-1}}$$&lt;/p&gt;

&lt;p&gt;(where $\mu_{k} = u_{k}(x_{k})$) that minimizes the expected cost (we take an expectation due to the random variable $w_{k}$). Given an initial state $x_{0}$, the expected cost of following a policy $\pi$ starting from $x_0$ is denoted as&lt;/p&gt;

&lt;p&gt;$$ J_{\pi}(x_{0}) = \mathbb{E}\big[g_{N}(x_{N}) + \sum_{k=0}^{N-1}g_{k}(x_{k}, u_{k}, w_{k})]$$&lt;/p&gt;

&lt;p&gt;An optimal policy $\pi^{*}$ is the one that minimizes this expected cost; i.e,&lt;/p&gt;

&lt;p&gt;$$ J_{\pi^{*}}(x_{0}) = \min_{\pi \in \Pi} J_{\pi}(x_{0})$$&lt;/p&gt;

&lt;p&gt;where $\Pi$ is the space of admissible policies.&lt;/p&gt;

&lt;h1 id=&#34;bellman-s-principle-of-optimality&#34;&gt;Bellman&amp;rsquo;s principle of optimality&lt;/h1&gt;

&lt;p&gt;Let $\pi^{*}={\mu_{0}^{*},..,\mu_{k}^{*},.. \mu_{N-1}^{*}}$ be an optimal policy of the problem stated above, and assume that when using $\pi^{*}$, a given state $x_{i}$ occurs at time $i$ with positive probability. Consider the subproblem, whereby we are at $x_{i}$ at time $i$ and wish to minimze the &amp;ldquo;cost-to-go&amp;rdquo; from time $i$ to time $N$&lt;/p&gt;

&lt;p&gt;$$ \mathbb{E}\bigg[g_{N}(x_{N}) + \sum_{k=i}^{N-1}g_{k}(x_{k}, u_{k}, w_{k})\bigg]$$&lt;/p&gt;

&lt;p&gt;Then the truncated policy ${\mu_{i}^{*},\mu_{i+1}^{*},.. \mu_{N-1}^{*}}$ is optimal for this subproblem.&lt;/p&gt;

&lt;p&gt;Intuitively, let us look at the following problem where we start from A and we need to reach the destination E, and the edge weights are the costs incurred for traversing that edge. The path that minimizes the cost is A-B-D-E. Equivalently, the decision (corresponds to choosing the next node) taken at each time step are B at k=0, D at k=1 and E at k=2. If the policy determined by the path A-B-D-E is optimal, then the truncated path B-D-E is also optimal. If it were not, then we can further reduce the cost by choosing the optimal path which contradicts the fact that A-B-D-E is the path with the minimum cost.&lt;/p&gt;

&lt;!-- ![DP](/img/DP1.png) --&gt;


&lt;figure&gt;
    
        &lt;img src=&#34;https://jayanthrr.github.io/img/DP1.png&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;DP Illustration&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;h1 id=&#34;dp-algorithm&#34;&gt;DP Algorithm&lt;/h1&gt;

&lt;p&gt;The DP algorithm proceeds as follows. We start from the last step of decision making ($N-1$) and proceed backwards performing the minimization&lt;/p&gt;

&lt;p&gt;$$ J_{N}(x_{N}) = g_{N}(x_{N}) $$&lt;/p&gt;

&lt;p&gt;$$ J_{k}(x_{k}) =\min_{u_{k} \in U_{k}(x_{k})}\mathbb{E}_{w_{k}}\bigg[g_{k}(x_{k}, u_{k}, w_{k}) + J_{k+1}(f_{k}(x_{k}, u_{k}, w_{k}))\bigg],$$
$$ k = 0,1,..,N-1$$&lt;/p&gt;

&lt;p&gt;where the expectation is taken with respect to the probability distribution of $w_{k}$ which is assumed to depend on $x_{k}, u_{k}$. Furthermore, if
$\mu^{*}_{k}=u_{k}^{*}(x_{k})$ minimizes the above equation, then the policy $\pi^{*}={\mu_{0}{*},&amp;hellip;,\mu_{k}{*},&amp;hellip;,\mu_{N-1}{*}}$ is optimal.&lt;/p&gt;

&lt;h1 id=&#34;example&#34;&gt;Example&lt;/h1&gt;

&lt;p&gt;Let us look at an example application of the above described DP algorithm. Consider a perfect binary tree of height N (i.e. each level k of the binary tree has $2^{k}$ nodes). The nodes are of two types, green and red. It is know before hand that each node can be red with probability $p$ and green with probability $1-p$. We shall call an arc as the line joining a node with one of it&amp;rsquo;s children. An arc is free if both the nodes are green, and is blocked if either of them is red. One can only traverse along free arcs, and the objective is to find if a free path (a sequence of free arcs) exists from the root to the leaves.&lt;/p&gt;

&lt;!-- ![breakthrough](/img/breakthrough.png) --&gt;


&lt;figure&gt;
    
        &lt;img src=&#34;https://jayanthrr.github.io/img/breakthrough.png&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;Free path&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;p&gt;One way to find an exact solution to the above problem is to use DP to start from the leaves (level N), and traverse backwards to check if a free path exists. In the $k^{th}$ step of the DP, the algorithm finds if a path exists from each node (at height $N-k$) to the leaves using the results from step $k-1$. The amount of computation at the $k^{th}$ step is $\mathcal{O}(2^{N-k})$ and there are $N$ steps in the algorithm. The overall runtime is of the order $\mathcal{O}(N2^{N})$. We can see from the plot that the run time increases exponentially with the height of the tree.&lt;/p&gt;

&lt;!-- ![runtime](/img/runtime.png) --&gt;


&lt;figure&gt;
    
        &lt;img src=&#34;https://jayanthrr.github.io/img/runtime.png&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;Run time plot&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;p&gt;In problems where finding an exact solution is not critical and finding an approximately correct solution (that works most of the time) is sufficient, faster heuristics can be employed to achieve a tradeoff between accuracy and computation. Let us use one such heuristic here that reduces the computation time drastically while offering a suboptimal solution.&lt;/p&gt;

&lt;p&gt;Consider a greedy algorithm which starts at the root node. If both the arcs from the root node are blocked, then the algorithm returns False (no path exists). If one of the arcs is free, it traverses down that arc to the child node and repeats the same with this node. If both the arcs are free, then it uses a fixed rule to choose which arc to traverse (say it chooses always the right arc). The runtime of this algorithm is $\mathcal{O}(N)$ which is extremely fast as compared to $\mathcal{O}(N2^{N})$. However, this algorithm always doesn&amp;rsquo;t output the correct solution. For example, in the above figure, this algorithm outputs False despite the existence of a free path (bold lines).&lt;/p&gt;

&lt;h1 id=&#34;one-step-lookahead&#34;&gt;One-step lookahead&lt;/h1&gt;

&lt;p&gt;One effective way to reduce the computation is to use an approximate cost-to-go function. In the DP algorithm, to obtain the control at $k$ we perform the minimization over all possible exact $J_{k+1}(f_{k}(x_{k}, u_{k}, w_{k}))$. Instead if we are able to approximate the cost to go of stage $k+1$ as $\tilde{J}_{k+1}(f_{k}(x_{k}, u_{k}, w_{k}))$, we can avoid the computation required to minimize over all the next stages. This is called a &lt;em&gt;one step lookahead policy&lt;/em&gt;, where at stage $k$ we perform the following minimization&lt;/p&gt;

&lt;p&gt;$$\bar{\mu}_{k}(x_{k}) = \arg \min_{u_{k} \in U_{k}(x_{k})}\mathbb{E}_{w_{k}}\bigg[g_{k}(x_{k}, u_{k}, w_{k}) + \tilde{J}_{k+1}(f_{k}(x_{k}, u_{k}, w_{k}))\bigg],$$
$$k = 0,1,..,N-1$$&lt;/p&gt;

&lt;p&gt;and the one step lookahead policy is denoted as
$\bar{\pi}=\{ \bar{\mu}_{0},&amp;hellip;,\bar{\mu}_{N-1} \}$&lt;/p&gt;

&lt;p&gt;Similarly, in a &lt;em&gt;two step lookahead policy&lt;/em&gt;, we use the same minimization as above, but instead of directly using $\tilde{J}_{k+1}(f_{k}(x_{k}, u_{k}, w_{k}))$, we obtain it as a minimization of a &lt;em&gt;one step lookahead approximation&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;$$ \tilde{J}_{k+1}(x_{k+1}) =\min_{u_{k+1} \in U_{k+1}(x_{k+1})}\mathbb{E}_{w_{k+1}}\bigg[g_{k+1}(x_{k+1}, u_{k+1}, w_{k+1}) + \\&lt;br /&gt;
 J_{k+2}(f_{k+1}(x_{k+1}, u_{k+1}, w_{k+1}))\bigg], k = 0,1,..,N-2$$&lt;/p&gt;

&lt;p&gt;where $\tilde{J}_{k+2}$ is an approximation of the cost-to-go of $J_{k+2}$. Intuitively, it can be described as solving a two level DP at every stage of the problem. If the cost-to-go function can be approximated fairly accurately, then this algorithm can provide an approximate solution in a much better run time as compared to solving the complete DP. Now arises the most important question, &lt;strong&gt;how do we approximate the cost-to-go function?&lt;/strong&gt; Infact, most of the recent research in this field is dedicated towards finding computationally feasible techniques that provide approximately accurate representations for the cost functions. Following are some types of approximation techniques,&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Problem approximation&lt;/strong&gt;: &lt;em&gt;Lookahead&lt;/em&gt; techniques described above approximate the problem to a limited number of steps at every stage of the algorithm&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Parametric cost approximation&lt;/strong&gt;: The cost-to-go functions are approximated from a parametric class of functions (for example, neural networks)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;On-line approximation&lt;/strong&gt;: A suboptimal policy is used on-line to approximate the cost-go-function. In this article, we shall look at Rollout algorithm that belongs to this approach&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Simulation-based approximation&lt;/strong&gt;: In the presence of a simulator that can accurately determine the state transitions of the problem, Monte Carlo simulations are used to approximate the cost functions.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;rollout&#34;&gt;Rollout&lt;/h1&gt;

&lt;p&gt;The Rollout algorithm is similar to a &lt;em&gt;one step lookahead&lt;/em&gt; algorithm in the sense that we find the control that minimizes the expression
$$\bar{\mu}_{k}(x_{k}) = \arg \min_{u_{k} \in U_{k}(x_{k})}\mathbb{E}_{w_{k}}\bigg[g_{k}(x_{k}, u_{k}, w_{k}) + \tilde{J}_{k+1}(f_{k}(x_{k}, u_{k}, w_{k}))\bigg],$$
$$k = 0,1,..,N-1$$&lt;/p&gt;

&lt;p&gt;where $\tilde{J}_{k+1}$ is the true cost-to-go of $J_{k+1}$ with respect to a suboptimal base policy $\pi$. The policy thus obtained $\bar{\pi}=\{ \bar{\mu}_{0},&amp;hellip;,\bar{\mu}_{N-1} \}$ is called the rollout policy. Since in the minimization, at each stage we always choose the control that minimizes the true cost-to-go of the suboptimal policy, the cost-to-go approximation is always less than or equal to the cost-to-go of the base policy. The rollout algorithm thus yields a policy better than the base policy. This technique is called as &lt;em&gt;policy improvement&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Let us now apply this rollout algorithm to the example we discussed above. The rollout algorithm proceeds as follows.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;If at a node, at least one of the two children is red, it proceeds exactly like the greedy algorithm.&lt;/li&gt;
&lt;li&gt;If at a node, both the children are green, rollout algorithm looks one step ahead, i.e. runs greedy policy on the children of the current node. If exactly one of these return True, the algorithm traverses that corresponding arc. If both of these return True, then the algorithm chooses one according to a fixed rule (choose the right child), and if both of them return False, then the algorithm returns False.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This seemingly very simple trick can lead to large performance gains while minimizing the computation required. If we look at the results below, we can observe that using rollout we can considerable improve on the accuracy of finding a free path, while keeping the amount of computation required close to that of the greedy policy. The implementation can be found &lt;a href=&#34;https://github.com/JayanthRR/approximate-dynamic-programming&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;


&lt;figure&gt;
    
        &lt;img src=&#34;https://jayanthrr.github.io/img/accuracy.png&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;Accuracy plot&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;



&lt;figure&gt;
    
        &lt;img src=&#34;https://jayanthrr.github.io/img/time.png&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;Runtime plot&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;In this post, we discussed the basic DP problem, formulation, algorithm and illustrated with an example the infeasibility of using the DP algorithm. In problems where a suboptimal solution is sufficient, we discussed the rollout algorithm that improves upon the performance of a greedy base policy while requiring minimal computation.&lt;/p&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;Bertsekas, D. P. (1995). Dynamic programming and optimal control (Vol. 1, No. 2). Belmont, MA: Athena scientific.&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Mechanism Design and Sponsored Search Auctions</title>
      <link>https://jayanthrr.github.io/post/sponsored/</link>
      <pubDate>Tue, 27 Feb 2018 12:40:58 -0500</pubDate>
      
      <guid>https://jayanthrr.github.io/post/sponsored/</guid>
      <description>

&lt;p&gt;If you are watching a video on You Tube and the video is paused for an annoying 30 sec advertisement, you probably should know the history behind on-line advertisements. In fact, advertising and internet helped each other attain their respective potentials. Without advertising, there wouldn&amp;rsquo;t be any Google or Facebook (may be not in the present form), and without any internet, you probably wouldn&amp;rsquo;t know about a tourist package in a remote island like Madeira.&lt;/p&gt;

&lt;p&gt;In this blog post, let us have a look at a mechanism design called &lt;a href=&#34;https://en.wikipedia.org/wiki/Sponsored_search_auction&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Sponsored Search Auctions&lt;/em&gt;&lt;/a&gt;, which is key to the rise of internet giants like Yahoo! and Google. We shall discuss the properties of such auctions along with examples to gain a better insight. This post is intended for general audience, and hence we shall try hard to not drift into game theoretic concepts (although it is impossible to do so at all times).&lt;/p&gt;

&lt;h1 id=&#34;sponsored-search-auctions&#34;&gt;Sponsored Search Auctions&lt;/h1&gt;

&lt;p&gt;Before diving into the topic, let us get familiar with auctions. &lt;a href=&#34;https://en.wikipedia.org/wiki/Auction&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Auction&lt;/em&gt;&lt;/a&gt; is the sale of items where the seller invites the buyers (bidders) to submit bids and makes a decision on whom to sell it to.  The bidders have their own valuations for the item and submit bids indicating their willingness to pay for it, and the seller allocates the item to the bidder he/she likes the most (usually it is the bidder with the highest bid).  For example, if you want to move to a new place but you do not want to carry some of your furniture/luggage, you put them on
eBay for an auction. If someone fails to repay their loan to a bank, the bank
auctions off the mortgaged property.&lt;/p&gt;

&lt;p&gt;Consider that you are planning to travel to Madeira with your friends. A quick internet search for the work &amp;lsquo;Madeira tours&amp;rsquo; results in a list of links some of which
are marked as &lt;em&gt;Ad&lt;/em&gt; sponsored by the respective websites. Whenever a user clicks
a sponsored link through the search engine, the advertiser pays a certain amount
to the search engine for facilitating their advertising. In &lt;em&gt;Sponsored Search Auctions&lt;/em&gt; for every keyword, the search engine allocates a certain number of slots, and multiple advertisers compete for these slots which provide different value to different advertisers. The probability of an advertiser $i$’s Ad being clicked when placed in a slot $j$ is called the &lt;strong&gt;Click Through Rate&lt;/strong&gt;, or CTR, denoted by $α_{ij}$ (this is simplified in various mechanisms). The per click value to advertiser $i$ is $s_{i}$ and the expected value on being assigned a slot $j$ is $α_{ij}s_i$.  The search engine must design an efficient mechanism that maximizes the welfare (or the revenue) by assigning the slots to different advertisers (bidders). Let us follow the convention of using search engine for the seller and advertiser for the bidder.&lt;/p&gt;

&lt;p&gt;Let us now look at some important properties of &lt;em&gt;Sponsored Search Auctions&lt;/em&gt; that differentiate it from traditional auctions.
- These auctions are dynamic in nature and the bidders can change their bids from
time to time. We may now not get the same list of links for searching &amp;lsquo;Madeira tours&amp;rsquo; if some bidders&amp;rsquo; algorithms modified their respective bids.
- The items at sale are perishable with time. If an item is unsold, it is of no value to the search engine at a later point of time, unlike a storable product such as a piece of furniture which still has some value in the future if unsold. The search engine though is not constrained by the quantity of items it can offer. It can potentially fill up the entire search results with &lt;em&gt;Ads&lt;/em&gt;. However, we may not use &lt;em&gt;Google Search&lt;/em&gt; if every search query returns only &lt;em&gt;Ads&lt;/em&gt;.
- The unit of what is being sold is different for the search engine and the advertiser. For the search engine, it is the space allotted to the advertiser every time a user searches for that particular key word. For the advertiser, it is the value of trade when a user clicks the sponsored link. In practice, the advertiser is charged based on the number of clicks (or the rate of it) the link receives.&lt;/p&gt;

&lt;h1 id=&#34;history-and-generalized-first-price-auctions&#34;&gt;History and Generalized First Price Auctions&lt;/h1&gt;

&lt;p&gt;In the early 1990s, when the era of internet advertising began, &lt;em&gt;Ads&lt;/em&gt; were sold on a per impression basis, which includes a flat fee paid by the advertiser to the search engine for showing their advertisement a fixed number of times. Internet advertising was then revolutionized by Overture in 1997 (later acquired by Yahoo!), with their design called as the &lt;a href=&#34;https://en.wikipedia.org/wiki/Generalized_first-price_auction&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Generalized First Price Auction&lt;/em&gt;&lt;/a&gt;. It is similar to a traditional open bid first price auction. The important features of this auction are as follows
- Advertisers can now target their &lt;em&gt;Ads&lt;/em&gt; for specific keywords instead of tickers or banners
- Advertisers can bid their willingness to pay on a per-click basis, instead of a flat price. The payments were also immediate and paid per click
- The bids were arranged in decreasing order, with the highest bid getting the slot with the highest CTR (usually the top most slot), the second highest bid getting the second best slot and so on.
- If an advertiser wins a slot, the advertiser has to pay value equal to their bid times the CTR of the slot.
- Advertisers also were allowed to change their bids frequently by looking at the other bids&lt;/p&gt;

&lt;p&gt;Owing to its novelty and advantages over the previous mechanisms, Overture&amp;rsquo;s GFP was a success and Yahoo! and MSN were among the top users of GFP. However, the mechanism itself was unstable and flawed.&lt;/p&gt;

&lt;h3 id=&#34;example&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;:&lt;/h3&gt;

&lt;p&gt;Consider that for a specific key word, there are three slots and four advertisers competing for the slots. The click through rates of the slots are 400, 200 and 100 (clicks per hour). The advertisers 1, 2, 3, 4 have values $ \$10, \$5, \$2, \$1$ respectively.Note that the advertisers know the values of the other bidders.&lt;/p&gt;

&lt;p&gt;Under the GFP mechanism, suppose advertiser 3 bids $ \$1.01$ to guarantee that he gets a slot (because advertiser 4 would not want to pay more than her value, i.e.  $\$1$). Noticing this, advertiser 2 would revise her bid to $ \$1.02$ because she does not need to pay more than that to get the second best slot. Similarly, advertiser 1 would want to revise the bid to $ \$1.03$ for the same reason. But advertiser can now revise the bid to $ \$1.04$ to win the top slot (CTR 400) which is four times more valuable than the third slot (CTR 100). And, the cycle continues.&lt;/p&gt;

&lt;p&gt;Clearly, there is no pure strategy equilibrium, and the competitive revision of bids continues. This gives an unfair advantage to bidders with high compute power to algorithmically outbid their competitors. Remember that the goal of the search engine is to maximize it&amp;rsquo;s own profit, the amount earned through the payments made by the bidders.&lt;/p&gt;

&lt;h1 id=&#34;generalized-second-price-auctions&#34;&gt;Generalized Second Price Auctions&lt;/h1&gt;

&lt;p&gt;Realizing that no bidder at position $i$ (in the decreasing order of bids) wants to pay more than the bidder at position $i+1$, as can be seen from the above example,
Google came up with their own pay-per-click system, called AdWords Select in February 2002. Their system follows a &lt;a href=&#34;https://en.wikipedia.org/wiki/Generalized_second-price_auction&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Generalized Second Price&lt;/em&gt;&lt;/a&gt; mechanism, where the advertiser at position $i$ pays the bid of the advertiser in position in $i+1$ plus a minimum increment (say $ \$0.01$). Let us consider the above example and evaluate payments made while employing a &lt;em&gt;GSP&lt;/em&gt; structure.&lt;/p&gt;

&lt;h3 id=&#34;example-1&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;:&lt;/h3&gt;

&lt;p&gt;Consider that the advertisers bid truthfully (i.e. bid their actual values). Then the three slots 1,2,3 go to advertisers 1,2,3 respectively.
- The payment made by advertiser 3 is $ \$101\ (=1.01\times 100)$ and the profit is $ \$99\ (=2\times100-101)$
- The payment made by advertiser 2 is $ \$402\ (=2.01\times200)$ and the profit is $ \$598\ (=5\times200-402)$
- The payment made by advertiser 1 is $ \$2004\ (=5.01\times400)$ and the profit is $ \$1996\ (=10\times400-2004)$&lt;/p&gt;

&lt;p&gt;The total payment received by the search engine is $ \$2507$. Contrastingly, in the &lt;em&gt;GFP&lt;/em&gt; example, there was no equilibrium payment like above.&lt;/p&gt;

&lt;p&gt;Let us consider another example when the advertisers do not bid truthfully.&lt;/p&gt;

&lt;h3 id=&#34;example-2&#34;&gt;&lt;strong&gt;Example&lt;/strong&gt;:&lt;/h3&gt;

&lt;p&gt;Consider that the CTRs of the three slots are comparable, say 400, 390, 380 respectively. Then if everyone bids truthfully, advertiser 1 pays $ \$2004$ and the profit is $ \$1996$. However, if advertiser underbids, say $ \$2.02$, he can still ensure slot 2. His payment is then $ \$3112=(10-2.02)\times390$ which is greater than $ \$1996$ if he bids truthfully.&lt;/p&gt;

&lt;p&gt;Despite the fact that &lt;em&gt;GSP&lt;/em&gt; doesn&amp;rsquo;t ensure truthful behavior, it is widely used because it is amazingly simple. It is interesting to note that most search engines including Google still use a variant of &lt;em&gt;GSP&lt;/em&gt;.&lt;/p&gt;

&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;Around two decades ago, innovative mechanism designs fueled the growth of on-line advertising and helped the dot com industry flourish. Today, the world is set to witness revolutionary changes in the way people move from one place to another. With autonomous ride sharing, ride hailing services becoming increasingly popular, we can expect new modes of advertising (may be call it in-transit advertising) with immersive multimedia technologies and what not. Recently
&lt;a href=&#34;http://fortune.com/2017/11/29/intel-partners-warner-bros-self-driving-cars/&#34; target=&#34;_blank&#34;&gt;Intel and Warner Bros&lt;/a&gt;  joined hands to develop tech to enhance immersive experience of riders for entertainment and advertising. I would not be surprised to expect a future where you subscribe to Ad-free rides by paying more.&lt;/p&gt;

&lt;p&gt;It is important to develop the tech to make autonomous vehicles safe for the public, but it is even more important to build revenue models that enable ride hailing services generate revenue to stay competitive. We can only wait and see how advertising (and mechanism design) can play its part in shaping the future of our transportation.&lt;/p&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;Edelman, B., Ostrovsky, M. and Schwarz, M., 2007. Internet advertising and the generalized second-price auction: Selling billions of dollars worth of keywords. American economic review, 97(1), pp.242-259.&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
  </channel>
</rss>
